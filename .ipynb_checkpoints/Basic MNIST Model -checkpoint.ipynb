{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing a Dataset\n",
    "mnist = tf.keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'tensorflow.keras.datasets.mnist' from '/Users/sal/Deep_Learning/Env/lib/python3.6/site-packages/tensorflow/keras/datasets/mnist/__init__.py'>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model with Spliting the Data in \n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = tf.keras.utils.normalize(x_train, axis=1)\n",
    "x_test = tf.keras.utils.normalize(x_test, axis=1)\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.08216044 0.2286589  0.3728098\n",
      "  0.30506548 0.08583808 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.08087653 0.38341541 0.36240278 0.37133624\n",
      "  0.48350001 0.4068725  0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.08861609 0.3824786  0.40758025 0.36240278 0.35218\n",
      "  0.44704564 0.43262392 0.06832372 0.00859123 0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.01621743\n",
      "  0.095788   0.36759266 0.42460179 0.40758025 0.36240278 0.29765841\n",
      "  0.16116667 0.43262392 0.30326141 0.17468832 0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.26434406\n",
      "  0.4023096  0.41354174 0.42460179 0.40758025 0.36240278 0.37133624\n",
      "  0.18419048 0.32446794 0.30326141 0.23912253 0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.08411834 0.38597476\n",
      "  0.40390606 0.41518278 0.32013627 0.18365276 0.36384089 0.33597088\n",
      "  0.09017659 0.13562417 0.30565873 0.2405544  0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.07427511 0.39255225 0.40867916\n",
      "  0.4023096  0.29374592 0.02021913 0.12082418 0.17401086 0.03094469\n",
      "  0.         0.         0.30326141 0.34794476 0.12263192 0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.04890249 0.2553207  0.41729294 0.37786605\n",
      "  0.33206506 0.13784725 0.         0.         0.         0.\n",
      "  0.         0.         0.30326141 0.36083161 0.40468535 0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.00966301 0.22906954 0.38994434 0.39585101 0.11514373\n",
      "  0.03033287 0.04594908 0.         0.         0.         0.\n",
      "  0.         0.         0.30326141 0.36083161 0.47826451 0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.07868449 0.32430069 0.38994434 0.10391089 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.30326141 0.36083161 0.47826451 0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.27332506 0.3255876  0.29400565 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.30565873 0.36226348 0.48071715 0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.33960736 0.33958568 0.32430069 0.17330859 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.30326141 0.36083161 0.3629905  0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.37982402 0.34786826 0.29598873 0.03868495 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.01343056 0.23176282 0.30326141 0.26632809 0.02943166 0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.37982402 0.34786826 0.28698037 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.0103149\n",
      "  0.25134326 0.43262392 0.26969888 0.10166287 0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.37982402 0.34786826 0.18660159 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.0690291  0.24313682\n",
      "  0.48350001 0.29699976 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.38429254 0.34924869 0.28955419 0.         0.         0.\n",
      "  0.         0.         0.         0.18365276 0.34226929 0.3728098\n",
      "  0.31082143 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.37982402 0.34786826 0.32043997 0.22592013 0.0791702  0.04703054\n",
      "  0.13569967 0.29210488 0.37910874 0.40758025 0.3206977  0.24608394\n",
      "  0.10744445 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.37982402 0.34786826 0.32430069 0.38994434 0.37770784 0.34867468\n",
      "  0.4023096  0.41354174 0.42460179 0.31575387 0.18695382 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.1251185  0.27470549 0.32430069 0.38994434 0.41729294 0.40867916\n",
      "  0.4023096  0.38236201 0.24431452 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.03451074 0.16472416 0.38994434 0.41729294 0.40867916\n",
      "  0.2251018  0.06071843 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 6s 108us/step - loss: 0.2629 - acc: 0.9234\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 6s 97us/step - loss: 0.1053 - acc: 0.9677: 0s - loss: 0.107\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 6s 97us/step - loss: 0.0730 - acc: 0.9766\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x122a67898>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 38us/step\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09479917257707567\n"
     ]
    }
   ],
   "source": [
    "print(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9707\n"
     ]
    }
   ],
   "source": [
    "#Model Accuracy\n",
    "print(val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
